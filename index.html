<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
        <title>Richard Zhang - UC Berkeley </title>
<style type="text/css"></style></head>
    <body><table border="0" width="980px" align="center"><tbody><tr><td>
    
        </td><td valign="top">
<!--            <img src="images/cmuscslogo.gif">
                <img src="images/rilogo.png"> -->
        <br>
        <table style="font-size: 11pt;" border="0" width="100%">
            <tbody><tr>
                <td width="50%">
                    <!-- <img width="300" src="./index_files/mypic.jpeg" border="0"> -->
                    <img width="300" src="./index_files/mypic2.jpg" border="0">
                </td>
                <td>
                    <font face="helvetica , ariel, &#39;sans serif&#39;" size="6"> 
                        <b>Richard Zhang</b><br><br>
                    </font>
                    <font face="helvetica , ariel, &#39;sans serif&#39;" size="4"> 
                        Research Scientist<br>
                        Adobe Research<br>
                        San Francisco, CA<br><br>
                        rizhang at adobe.com<br>
                        [<a href="https://github.com/richzhang" border="0">GitHub</a>]
                        [<a href="https://scholar.google.com/citations?user=LW8ze_UAAAAJ&hl=en" border="0">Google Scholar</a>]<br>
                     <!--   CV: <a href="CV.pdf">PDF</a> <br> -->
                    </font>
                </td>
            </tr>
        </tbody></table> 
        <p>
        </p><hr size="2" align="left" noshade="">
        <p>
        
        <font face="helvetica, ariel, &#39;sans serif&#39;"> 
        <!--</font></p><h2><font face="helvetica, ariel, &#39;sans serif&#39;">About Me</font></h2><font face="helvetica, ariel, &#39;sans serif&#39;">-->
        I recently joined Adobe Research as a Research Scientist. I was previously a PhD student at UC Berkeley, advised by Professor <a href="http://www.eecs.berkeley.edu/~efros/">Alexei (Alyosha) Efros</a>. I obtained my BS and MEng degrees from Cornell University in ECE. My research interests are in computer vision, machine learning, deep learning, graphics, and image procesing.

        <!-- <br><br> -->
        </p><hr size="2" align="left" noshade="">     
        <h2>Internship </h2>
        <font face="helvetica, ariel, &#39;sans serif&#39;">
            <span style="font-size: 10pt;">
            If you have similar interests and are interested in collaborating during a summer 2019 internship, feel free to contact me. Please tell me about your past research experience and what you would potentially like to do. The goal of an internship is a publication, typically CVPR or SIGGRAPH (see my two most recent publications, which were from my summer 2017 internship). Interns are typically PhD students. The number of slots is limited, so we unfortunately cannot accept everyone.
            </span>
           
        </p><hr size="2" align="left" noshade="">     

        <h2>News </h2>
        <font face="helvetica, ariel, &#39;sans serif&#39;">
            <span style="font-size: 10pt;">
            <b>[Aug 2018]</b> I will be presenting at the Thesis Fast Forward session at SIGGRAPH on Tuesday 8/14, 2:00pm.<br>
            <b>[Jun 2018]</b> We will be presenting our <a href="https://richzhang.github.io/PerceptualSimilarity/">project</a> on perceptual metrics at CVPR, Tuesday 6/19, 10:10am. <b><i>Try our metric <a href="https://github.com/richzhang/PerceptualSimilarity">here</a>!</i></b><br>
            <b>[May 2018]</b> I have <a href="./index_files/graduation.jpg">graduated</a> from UC Berkeley and have joined Adobe Research as a Research Scientist in San Francisco!
            </span>

        </p><hr size="2" align="left" noshade="">

        <h2>Publications </h2>
        <font face="helvetica, ariel, &#39;sans serif&#39;">
            <table cellspacing="15">
				<tbody>
                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <img width="250" align="center" src="./index_files/perceptual_teaser.jpg" border="0">
                            </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>The Unreasonable Effectiveness of Deep Features as a Perceptual Metric</b> <br>
                        <span style="font-size: 10pt;">
                        Richard Zhang, <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>, <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>, 
                        <a href="https://research.adobe.com/person/eli-shechtman/">Eli Shechtman</a>, <a href="http://www.oliverwang.info/">Oliver Wang</a><br>
                        In CVPR, 2018. <br>
                        [<a href="http://arxiv.org/abs/1801.03924">Paper</a>]
                        [<a href="https://richzhang.github.io/PerceptualSimilarity/">Webpage</a>]
                        [<a href="https://github.com/richzhang/PerceptualSimilarity">GitHub</a>]
                        [<a href="https://richzhang.github.io/PerceptualSimilarity/index_files/poster_cvpr.pdf">Poster</a>]
                        [<a href="https://research.adobe.com/with-deep-learning-computers-see-images-more-like-humans-do/">Adobe Blog</a>]
                        [<a href="https://www.youtube.com/watch?v=DglrYx9F3UU">Two Min Papers</a>]
                        [<a href="./index_files/bibtex_cvpr2018.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>
                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <img width="250" align="center" src="./index_files/nips2017.jpg" border="0">
                            </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Toward Multimodal Image-to-Image Translation</b> <br>
                        <span style="font-size: 10pt;">
                        <a href="http://people.eecs.berkeley.edu/~junyanz/">Jun-Yan Zhu</a>, Richard Zhang, <a href="http://people.eecs.berkeley.edu/~pathak/">Deepak Pathak</a>, <a href="https://people.eecs.berkeley.edu/~trevor/">Trevor Darrell</a>, <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>, <a href="http://www.oliverwang.info/">Oliver Wang</a>, 
                        <a href="https://research.adobe.com/person/eli-shechtman/">Eli Shechtman</a> <br>
                        In NIPS, 2017. <br>
                        [<a href="https://arxiv.org/abs/1711.11586">Paper</a>]
                        <!-- <a href="https://papers.nips.cc/paper/6650-toward-multimodal-image-to-image-translation">Official</a>] -->
                        [<a href="https://junyanz.github.io/BicycleGAN/">Webpage</a>]
                        [<a href="https://github.com/junyanz/BicycleGAN">GitHub</a>]
                        [Video (<a href="https://www.youtube.com/watch?v=JvGysD2EFhw">YouTube</a>)(<a href="http://efrosgans.eecs.berkeley.edu/BicycleGAN/video_extended.mp4">mp4</a>)]
                        [<a href="http://junyanz.github.io/BicycleGAN/index_files/poster_nips_v3.pdf">Poster</a>]
                        [<a href="https://www.youtube.com/watch?v=XcxzKLrCpyk">Two Min Papers</a>]
                        [<a href="./index_files/bibtex_nips2017.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>
                <tr>
                    <td width="30%" align=left>
                    <!-- height="74" -->
                        <a href="http://richzhang.github.io/ideepcolor"><img width="250" align="center" src="./index_files/siggraph2017_update.jpg" border="0"></a>
                            </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Real-Time User-Guided Image Colorization with Learned Deep Priors</b> <br>
                        <span style="font-size: 10pt;">
                        Richard Zhang*, <a href="http://people.eecs.berkeley.edu/~junyanz/">Jun-Yan Zhu</a>*, <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>, <a href="http://young-geng.xyz/">Xinyang Geng</a>, Angela S. Lin, Tianhe Yu, 
                        <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>        <br>
                        (*indicates equal contribution) <br>
                        In SIGGRAPH, 2017. <br>
                        [<a href="https://arxiv.org/abs/1705.02999">Paper</a>]
                        <!-- <a href="https://dl.acm.org/citation.cfm?id=3073703">Official</a>] -->
                        [<a href="https://richzhang.github.io/ideepcolor/">Webpage</a>]
                        [<a href="https://youtu.be/eiFzQI7LzO0?t=5690">Fastforward</a>]
                        [<a href="https://www.youtube.com/watch?v=rp5LUSbdsys">Talk</a>]
                        [Video (<a href="https://www.youtube.com/watch?v=eL5ilZgM89Q&feature=youtu.be">YouTube</a>)(<a href="https://www.dropbox.com/s/mfi66auuv7qzyx0/iColor_release.mp4?dl=0">mp4</a>)]
                        [<a href="https://github.com/junyanz/interactive-deep-colorization">GitHub</a>]
                        [<a href="https://www.dropbox.com/s/urmifx558nw0ogi/release.pptx?dl=0">Slides</a> (141mb)]
                        [<a href="./index_files/bibtex_siggraph2017.txt">Bibtex</a>]
                        <br>

                    </td>
                </tr>
                <tr>
                    <td width="30%" align=left>
                        <a href="http://richzhang.github.io/splitbrainauto"><img width="250" align="center" src="./index_files/cvpr2017_splitbrain.png" border="0"></a>
                            </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Split-Brain Autoencoders: Unsupervised Learning by Cross-Channel Prediction</b><br>
                        <span style="font-size: 10pt;">
                        Richard Zhang, <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>,
                        <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>        <br>
                        In CVPR, 2017.
                        <br>
                        [<a href="https://arxiv.org/abs/1611.09842">Paper</a>]
                        <!-- (<a href="http://openaccess.thecvf.com/content_cvpr_2017/html/Zhang_Split-Brain_Autoencoders_Unsupervised_CVPR_2017_paper.html">official</a>)] -->
                        [<a href="http://richzhang.github.io/splitbrainauto">Webpage</a>]
                        [<a href="https://github.com/richzhang/splitbrainauto">GitHub</a>]
                        [<a href="https://richzhang.github.io/splitbrainauto/index_files/poster_cvpr.pdf">Poster</a>]
                        [<a href="https://www.youtube.com/watch?v=FTzcFsz2xqw">Seminar Talk</a>]
                        [<a href="./index_files/bibtex_cvpr2017_splitbrain.txt">Bibtex</a>]</span>
                    </td>
                </tr>
                <tr>
                    <td width="30%" align=left>
                    <!-- height="90" -->
                        <a href="http://richzhang.github.io/colorization/"><img width="250" align="center" src="./index_files/arxiv2016_colorization.jpg" border="0"></a>
                        </td>
                        <td>
                        <span style="font-size: 12pt;"><b>Colorful Image Colorization</span></b><br>
                        <span style="font-size: 10pt;">
                        Richard Zhang, <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>,
                        <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>        <br>
                        In ECCV, 2016 (oral presentation).
                        <br>
                        [<a href="https://arxiv.org/abs/1603.08511">Paper</a>]
                        <!-- <a href="https://link.springer.com/chapter/10.1007/978-3-319-46487-9_40">Official</a>] -->
                        [<a href="http://richzhang.github.io/colorization/">Webpage</a>]
                        [<a href="https://github.com/richzhang/colorization">GitHub</a>]
                        [<a href="http://videolectures.net/eccv2016_zhang_image_colorization/">Talk</a>]
                        [<a href="https://www.dropbox.com/s/sa8m3y1ymj0ihct/presentation_eccv_release.pptx?dl=0">Slides</a> (138mb)]
                        [<a href="http://www.eccv2016.org/files/posters/O-2B-03.pdf">Poster</a>]
                        [<a href="./index_files/bibtex_eccv2016_colorization.txt">Bibtex</a>]
                    </td>
                </tr>
                <tr>

					<td width="30%" align=left>
						<img width="250" align="center" src="./index_files/icra2015.png" border="0">
                    </td>
					<td>
                        <span style="font-size: 12pt;">
                        <b>Sensor Fusion for Semantic Segmentation of Urban Scenes</b><br>
                        <span style="font-size: 10pt;"> 
						Richard Zhang, Stefan Candra, </a><a href="http://anp.lbl.gov/kai-vetter/">Kai Vetter</a>,
                        <a href="http://www-video.eecs.berkeley.edu/~avz/">Avideh Zakhor</a>		<br>
						In ICRA, 2015.
                        <br>
                        [Paper (<a href="./index_files/icra2015.pdf">pdf</a>)(<a href="http://ieeexplore.ieee.org/document/7139439/">official</a>)]

                        [<a href="./index_files/pres_icra2015.pdf">Slides</a>]
                        [<a href="./index_files/poster_icra2015.pdf">Poster</a>]
                        [<a href="https://www.youtube.com/watch?v=s9X63Ma3M0Y">Talk</a>]

                        [Annotations (<a href="http://www.eecs.berkeley.edu/~rich.zhang/projects/2015_ICRA_semanticsegmentation/KITTI_public.tar">tar</a>)(<a href="http://www.eecs.berkeley.edu/~rich.zhang/projects/2015_ICRA_semanticsegmentation/KITTI_public.zip">zip</a>) ]
                        [<a href="./index_files/bibtex_icra2015.txt">Bibtex</a>]
                        </span>
					</td>
				</tr>  
                <tr>
                    <td width="30%" align="center">
                    <!-- height="100" -->
                        <img height="95" horizontal-align="center" src="./index_files/wacv2014.png" border="0">
                            </td>
                    <td>
                        <span style="font-size: 12pt;"><b>Automatic Identification of Window Regions on Indoor Point Clouds Using LiDAR and Cameras</b><br>
                        <span style="font-size: 10pt;">
                        Richard Zhang,
                        <a href="http://www-video.eecs.berkeley.edu/~avz/">Avideh Zakhor</a>
                        <br>
                        In WACV, 2014.
                        <br>
                        [Paper (<a href="./index_files/wacv2014.pdf">pdf</a>)(<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.649.303&rep=rep1&type=pdf">official</a>)]

                        [<a href="./index_files/bibtex_wacv2014.txt">Bibtex</a>]
                        </span>
                    </td>
                </tr>

            </tbody></table>

        <h2>Thesis </h2>
        <font face="helvetica, ariel, &#39;sans serif&#39;">
            <table cellspacing="15">
                <tbody>
                <tr>
                    <td width="30%" align=left>
                        <img width="250" align="center" src="./index_files/berkeley_logo.png" border="0">
                            </td>
                    <td>
                        <span style="font-size: 12pt;">
                        <b>Image Synthesis for Self-Supervised Visual Representation Learning</b> <br>
                        <span style="font-size: 10pt;">
                        Richard Zhang<br>
                        <!-- Commitee: Alexei A. Efros, Trevor Darrell, Michael DeWeese.<br> -->
                        Spring 2018.<br>
                        [<a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2018/EECS-2018-36.html">Thesis</a>]
                        [<a href="https://www.youtube.com/watch?v=aGhYitrOJRc">Dissertation Talk</a>]
                        [<a href="https://youtu.be/IXG-uWFAkmM">Fast Forward</a>]
                        [<a href="https://www.dropbox.com/s/96f0xhfwvjnbf52/presentation_dissertation.pptx?dl=0">Slides</a> (396 MB)]
                        [<a href="./index_files/bibtex_thesis.txt">Bibtex</a>]
                        <br>
                    </td>
                </tr>
            </tbody></table>

        <h2>Teaching </h2>
        <!-- <a href="https://research.adobe.com/fellowship/">Adobe Research Fellowship</a> 2017 -->
        <span style="font-size: 12pt;">
        <b>Introduction to Artificial Intelligence (CS 188)</b>, UC Berkeley <br>
        <span style="font-size: 10pt;">
        Graduate Student Instructor (GSI) with Prof. <a href="http://people.eecs.berkeley.edu/~anca/">Anca Dragan</a> <br>
        Spring 2017<br>
        <br>
        <span style="font-size: 12pt;">
        <b>Computer Vision (CS 280)</b>, UC Berkeley <br>
        <span style="font-size: 10pt;">
        Graduate Student Instructor (GSI) with Prof. <a href="http://people.eecs.berkeley.edu/~efros/">Alexei A. Efros</a>, Prof. <a href="http://people.eecs.berkeley.edu/~trevor/">Trevor Darrell</a> <br>
        Spring 2016<br>
        <br>
        <span style="font-size: 12pt;">
        <b>Introduction to Circuits (ECE 2100)</b>, Cornell University <br>
        <span style="font-size: 10pt;">
        Teaching Assistant (TA) with Prof. <a href="https://molnargroup.ece.cornell.edu/">Alyosha Molnar</a> <br>
        Spring 2010<br>
        <br>

        <h2>Awards </h2>
        <span style="font-size: 10pt;">
        Thesis Fast Forward, Best Presentation, SIGGRAPH 2018<br>
        <a href="https://research.adobe.com/fellowship/">Adobe Research Fellowship</a> 2017
        </span><br>
<!--         <font face="helvetica, ariel, &#39;sans serif&#39;">
            <table cellspacing="25">
                <tbody>
                <tr>
                    <td width="30%" align="center">
                        <img height="75" horizontal-align="center" src="./index_files/Adobe-logo.png" border="0">
                            </td>
                    <td>
                        <a href="https://research.adobe.com/fellowship/">Adobe Research Fellowship</a> 2017
                    </td>
                </tr>
            </tbody></table>
        </font> -->

        <br>

        <h2>Mentorship</h2>
        I have had the opportunity to work with some talented students.
        <p>
          
        <!--
        <dl class="dl-horizontal">
          <dt>Current Undergrads</dt>
        </dl>
        -->
        <!-- <dl class="dl-horizontal"> -->
            <dt><b>Undergraduate Researchers</b></dt>
            Sheng-Yu Wang<br>
            <a href="https://www.linkedin.com/in/hemangjangle/">Hemang Jeetendra Jangle</a><br>
            Xin Qin (now @ USC)<br>
            <a href="http://www.cs.utexas.edu/~alin/">Angela S. Lin</a> (now @ UT Austin)<br>
            <a href="http://young-geng.xyz/">Xinyang Geng</a> (now @ UC Berkeley)<br>
            <a href="https://tianheyu927.github.io/">Tianhe Yu</a> (now @ Stanford)<br>
            Stefan A. Candra<br>
        <!-- </dl> -->
        </p>


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-75897335-1', 'auto');
  ga('send', 'pageview');
</script>
            
</font></td></tr></tbody></table><iframe frameborder="0" scrolling="no" style="border: 0px; display: none; background-color: transparent;"></iframe><div id="GOOGLE_INPUT_CHEXT_FLAG" input="null" input_stat="{&quot;tlang&quot;:true,&quot;tsbc&quot;:true,&quot;pun&quot;:true,&quot;mk&quot;:false,&quot;ss&quot;:true}" style="display: none;"></div></body></html>
